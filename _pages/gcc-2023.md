---
layout: page
title: Global Cyber Conference 2023
permalink: /gcc-2023
description: Webpage of "Global Cybersecurity Threat Landscape in the Age of AI" and "How AI Is Changing the Security of Software Systems" by Prof. Dr. Guido Salvenschie, MSc David Spielmann, and MSc Daniel Sokolowski on September 15, 2023, at the Global Cyber Conference in Zurich, Switzerland.
---

We are part of the [Global Cyber Conference 2023](https://globalcyberconference.com/){: target="_blank"} on September 14 and 15, 2023, in Zurich. Please feel welcome to contact us to start a new or continue an existing discussion. Below you find more about [Prof. Dr. Guido Salvaneschi's keynote](#keynote) and our [expert focus panel discussion](#panel-discussion).

{% assign members = site.members | sort: "lastname" %}
<div class="d-flex flex-wrap align-content-stretch justify-content-center m-n2 pt-5 no-gutters">
    {% for member in members %}
        {% if member.lastname == "Spielmann" or member.lastname == "Sokolowski" or member.lastname == "Salvaneschi" %}
            <div class="col-6 col-sm-3 col-md-2 mb-3">
                <a href="{{ member.url | relative_url }}" class="no-decoration">
                    <div class="card hoverable h-100 m-2">
                        <img src="{{ '/assets/img/' | append: member.profile.image | relative_url }}" class="card-img-top" alt="{{ member.profile.name }}" />
                        <div class="card-body p-2">
                            <div class="card-title m-0">{{ member.title }}</div>
                        </div>
                    </div>
                </a>
            </div>
        {% endif %}
    {% endfor %}
</div>

<h2 id="keynote">Global Cybersecurity Threat Landscape in the Age of AI</h2>

*Keynote by [Prof. Dr. Guido Salvaneschi]({{ '/members/salvaneschi' | relative_url }}), September 14, 2023, 9:50 – 10:00 at Gallery.*

<h2 id="panel-discussion">How AI Is Changing the Security of Software Systems</h2>

*Expert focus panel discussion by [Prof. Dr. Guido Salvaneschi]({{ '/members/salvaneschi' | relative_url }}), [MSc Daniel Sokolowski]({{ '/members/sokolowski' | relative_url }}), and [MSc David Spielmann]({{ '/members/spielmann' | relative_url }}), September 15, 2023, 11:00 – 11:30 at Ballroom.*

[Slides of the session.]({{ '/assets/pdf/slides/GlobalCyberConf2023.pdf' | relative_url }}){: target="_blank"}

Below we provide a structured reading list of the discussion. Click on a topic to unfold a list of references with short summaries. Click on an entry's title to open the article. For each article, we tag its <span class="badge badge-primary">outlet type</span> <span class="badge badge-secondary">content type</span> and highlight the best ones with a <span class="badge badge-danger">recommended</span> read label. We refer to all online articles in the version displayed on September 15, 2023.

<a data-toggle="collapse" data-target="dl" href="#panel-discussion" role="button">Toggle all topics</a>

<h5><a data-toggle="collapse" href="#one" role="button">
    <i class="fas fa-chevron-down"></i> AI has long been used in cybersecurity, but LLMs have recently brought dramatic change.
</a></h5>
<dl class="collapse" id="one">
    <dt><span class="badge badge-primary">research</span> <span class="badge badge-secondary">insight</span> D.E. Denning. <a target="_blank" href="https://doi.org/10.1109/TSE.1987.232894">An Intrusion-Detection Model</a>. TSE. February&nbsp;1987</dt>
    <dd>The paper describes an AI-based expert system that scans real-time audit records to detect abnormal activities and potential security breaches, adaptable to various systems.</dd>
    <dt><span class="badge badge-primary">research</span> <span class="badge badge-secondary">insight</span> R.P. Lippmann et al. <a target="_blank" href="https://doi.org/10.1109/DISCEX.2000.821506">Evaluating Intrusion Detection Systems: The 1998 DARPA Off-line Intrusion Detection Evaluation</a>. DISCEX. 1998</dt>
    <dd>The paper evaluates a test bed for AI-based intrusion detection systems, finding that while they can moderately detect known attacks, they are less effective at identifying new or novel threats, indicating a need for more adaptive approaches.</dd>
    <dt><span class="badge badge-primary">white paper</span> <span class="badge badge-secondary">overview</span> Kaspersky <a target="_blank" href="https://media.kaspersky.com/en/enterprise-security/Kaspersky-Lab-Whitepaper-Machine-Learning.pdf">Machine Learning for Malware Detection</a>. 2021</dt>
    <dd>An overview of AI techniques for malware detection.</dd>
    <dt><span class="badge badge-primary">research</span> <span class="badge badge-secondary">broad insight</span> D. Arp et al. <!--Daniel Arp, Erwin Quiring†, Feargus Pendlebury‡§, Alexander Warnecke†, Fabio Pierazzi, Christian Wressnegger, Lorenzo Cavallaro‖, Konrad Rieck.--> <a target="_blank" href="https://arxiv.org/abs/2010.09470">Dos and Don'ts of Machine Learning in Computer Security</a>. USENIX-Security. November&nbsp;2021</dt>
    <dd>The paper critically examines the use of machine learning in computer security, identifying common pitfalls in design, implementation, and evaluation that can undermine system performance. Through a study of 30 papers and empirical analysis, it confirms these issues are widespread and offers actionable recommendations for improvement and directions for future research.</dd>
	<dt><span class="badge badge-danger">recommended</span> <span class="badge badge-primary">blog</span> <span class="badge badge-secondary">insight</span> OpenAI. <a target="_blank" href="https://openai.com/blog/chatgpt">Introducing ChatGPT</a>. November&nbsp;2022</dt>
	<dd>OpenAI's release article for <a target="_blank" href="https://openai.com/chatgpt">ChatGPT</a>.</dd>
    <dt><span class="badge badge-danger">recommended</span> <span class="badge badge-primary">blog</span> <span class="badge badge-secondary">insight</span> D. Johnshon. <!--Derek B. Johnson.--> <a target="_blank" href="https://www.scmagazine.com/analysis/how-chatgpt-is-changing-the-way-cybersecurity-practitioners-look-at-the-potential-of-ai">How ChatGPT is changing the way cybersecurity practitioners look at the potential of AI</a>. December&nbsp;2022</dt>
    <dd>The article discusses the cybersecurity community's complex reactions to ChatGPT's capabilities and vulnerabilities. While some security professionals find its machine learning capabilities useful for both defensive and offensive tasks, concerns arise about its dual-use nature and how easily its ethical safeguards can be bypassed.</dd>
    <!--<dt><span class="badge badge-primary">blog</span> <span class="badge badge-secondary">overview</span> T. Dureja. <!-Tanmay Dureja.-> <a target="_blank" href="https://durejatanmay.medium.com/artificial-intelligence-and-machine-learning-in-computer-security-e83848737e91">Artificial Intelligence and Machine Learning in Computer Security</a>. May&nbsp;2019</dt>
    <dd>A pre-LLM article on the role of AI in cybersecurity, highlighting the utility in tasks like anti-malware and risk analysis but also noting their limitations in decision-making and false positives. It emphasizes the irreplaceable value of human intuition and critical thinking in cybersecurity efforts, stating that AI and ML should serve as tools to aid humans rather than replace them.</dd>-->
	<!--<dt><span class="badge badge-primary">research</span> <span class="badge badge-secondary">broad insight</span> S. Bubeck et al. <!-Sébastien Bubeck, Varun Chandrasekaran, Ronen Eldan, Johannes Gehrke, Eric Horvitz, Ece Kamar, Peter Lee, Yin Tat Lee, Yuanzhi Li, Scott Lundberg, Harsha Nori, Hamid Palangi, Marco Tulio Ribeiro, Yi Zhang.-> <a target="_blank" href="https://arxiv.org/abs/2303.12712">Sparks of Artificial General Intelligence: Early experiments with GPT-4</a>. April&nbsp;2023</dt>
	<dd>Detailed experiments by Microsoft Research on the capabilities and limitations of GPT-4, including topics like multimodal composition, coding, maths, and interaction with the world and humans. They conclude that the performance is often human-like and that GPT-4 could be seen as an early Artificial General Intelligence (AGI).</dd>-->
	<!--<dt><span class="badge badge-primary">research</span> <span class="badge badge-secondary">broad insight</span> Gartner. <a target="_blank" href="https://www.gartner.com/en/information-technology/trends/top-technology-trends-ai-security-gb-pd">Gartner's 2023 Top Strategic Technology Trends</a>. 2023</dt>
	<dd>Section 3 identifies AI Trust, Risk and Security Management (AI TRiSM) as a top trend. They predict that companies with focus on automated TRiSM will reach by 2026 50% improvements in their business goals and user adoption.</dd>-->
</dl>

<h5><a data-toggle="collapse" href="#two" role="button">
    <i class="fas fa-chevron-down"></i> AI can be used on both sides to improve attacks as well as defense.
</a></h5>
<dl class="collapse" id="two">
    <dt><span class="badge badge-primary">blog</span> <span class="badge badge-secondary">overview</span> <span class="badge badge-secondary">insight</span> A. Joshi, D. Kerr. <!--Apoorva Joshi, Devon Kerr.--> <a target="_blank" href="https://www.elastic.co/blog/ai-offense-can-chatgpt-be-used-for-cyberattacks">AI on offense: Can ChatGPT be used for cyberattacks?</a>. May&nbsp;2023</dt>
    <dd>The article explores the potential for generative AI models like GPT-4 to assist in cyberattacks, concluding that while these models can aid attackers in certain steps, they lack the autonomy and broad capabilities to execute sophisticated attacks end-to-end. It also highlights that AI can empower both defenders and offenders in cybersecurity, emphasizing the human responsibility to use such technologies wisely.</dd>
</dl>

<h5><a data-toggle="collapse" href="#three" role="button">
    <i class="fas fa-chevron-down"></i> Concerns about improved phishing attacks have been raised early in media.
</a></h5>
<dl class="collapse" id="three">
    <dt><span class="badge badge-primary">news</span> <span class="badge badge-secondary">insight</span> A. Hern, D. Milmo. <!--Alex Hern, Dan Milmo.--> <a target="_blank" href="https://www.theguardian.com/technology/2023/mar/29/ai-chatbots-making-it-harder-to-spot-phishing-emails-say-experts">AI Chatbots Making It Harder to Spot Phishing Emails, say experts</a>. The Guardian. March&nbsp;2023</dt>
    <dd>Experts warn that AI chatbots like ChatGPT are making it harder to detect phishing emails by eliminating common giveaways like poor grammar and spelling. Data indicates a rise in bot-written phishing emails that are linguistically complex and less likely to be caught by spam filters, raising concerns about the technology's role in cybercrime.</dd>
    <dt><span class="badge badge-primary">news</span> <span class="badge badge-secondary">insight</span> E. Sayegh. <!--Emil Sayegh.--> <a target="_blank" href="https://www.forbes.com/sites/emilsayegh/2023/04/11/almost-human-the-threat-of-ai-powered-phishing-attacks/?sh=265771073bc9">Almost Human: The Threat Of AI-Powered Phishing Attacks</a>. Forbes. April&nbsp;2023</dt>
    <dd>AI is increasingly being used by cybercriminals to create highly convincing phishing attacks, making it easier to deceive individuals through emails, SMS, and even deep-faked voice calls. The rise of AI-powered attacks is leading to an "arms race" between hackers and cybersecurity professionals, necessitating advanced AI-based security solutions and increased public awareness.</dd>
    <dt><span class="badge badge-primary">news</span> <span class="badge badge-secondary">insight</span> B. Violino. <!--Bob Violino.--> <a target="_blank" href="https://www.cnbc.com/2023/06/08/ai-is-helping-hackers-make-better-phishing-emails.html">A.I. is Helping Hackers Make Better Phishing Emails</a>. CNBC. June&nbsp;2023</dt>
    <dd>AI is making it easier for cybercriminals to craft convincing phishing emails, posing new challenges for cybersecurity experts. To counter AI-assisted attacks, experts recommend organizations deploy AI-based defensive tools and update employee training on recognizing AI-enabled phishing campaigns.</dd>
    <dt><span class="badge badge-danger">recommended</span> <span class="badge badge-primary">blog</span> <span class="badge badge-secondary">insight</span> Microsoft. <a target="_blank" href="https://www.microsoft.com/en-us/microsoft-365-life-hacks/privacy-and-safety/how-ai-changing-phishing-scams">How AI is changing phishing scams</a>. July&nbsp;2023</dt>
    <dd>AI technology like ChatGPT is making phishing attacks increasingly sophisticated, enabling scammers to produce more convincing and targeted emails and even voice cloning for deceptive calls. While this poses new security challenges, the advancement in AI also offers the potential for improved defense mechanisms, including real-time threat identification and predictive cybersecurity measures.</dd>
</dl>

<h5><a data-toggle="collapse" href="#four" role="button">
    <i class="fas fa-chevron-down"></i> Generally, AI can assist in coding malware and may democratize attacks.
</a></h5>
<dl class="collapse" id="four">
	<dt><span class="badge badge-primary">blog</span> <span class="badge badge-secondary">insight</span> R. Morrison. <!--Ryan Morrison.--> <a target="_blank" href="https://techmonitor.ai/technology/ai-and-automation/chatgpt-cyberattacks-openai">Here’s how OpenAI’s ChatGPT can be used to launch cyberattacks</a>. Tech Monitor. December&nbsp;2022</dt>
    <dd>ChatGPT's ease in generating code and mimicking human language raises concerns about its potential misuse for sophisticated cyberattacks.</dd>
    <dt><span class="badge badge-danger">recommended</span> <span class="badge badge-primary">blog</span> <span class="badge badge-secondary">overview</span> M. Hill. <!--Michael Hill--> <a target="_blank" href="https://www.csoonline.com/article/575205/5-ways-threat-actors-can-use-chatgpt-to-enhance-attacks.html">5 Ways Threat Actors Can Use ChatGPT to Enhance Attacks</a>. CSO Online. April&nbsp;2023</dt>
	<dd>Further ideas of how cybercriminals can leverage ChatGPT for improved attacks.</dd>
    <dt><span class="badge badge-primary">news</span> <span class="badge badge-secondary">insight</span> P. Muncaster. <!--Phil Muncaster.--> <a target="_blank" href="https://www.infosecurity-magazine.com/news/experts-warn-chatgpt-democratize/">Experts Warn ChatGPT Could Democratize Cybercrime</a>. Infosecurity magazine. December&nbsp;2022</dt>
    <dd>Security experts warn that the capabilities of AI chatbots like ChatGPT can lower the barrier to entry for cyber-criminals by helping them craft more effective attacks and even develop malware. While the AI is programmed to avoid directly generating harmful content, it can still inadvertently assist in malicious activities, highlighting the need for more robust preventative measures against abuse.</dd>
	<dt><span class="badge badge-primary">blog</span> <span class="badge badge-secondary">insight</span> Analytics Insight. <a target="_blank" href="https://www.analyticsinsight.net/cybercriminals-are-using-chatgpt-to-create-hacking-tools-and-code/">Cybercriminals are Using ChatGPT to Create Hacking Tools and Code</a>. January&nbsp;2023</dt>
	<dd>Security researchers, including Israeli firm Check Point, have found that both experienced and novice hackers are increasingly using ChatGPT to develop hacking tools, code for malware, and phishing emails, raising concerns about the chatbot's impact on cybersecurity. The report suggests that while ChatGPT can be used for beneficial purposes, its accessibility and capabilities also make it easier for cybercriminals with minimal programming experience to create dangerous tools, requiring urgent attention from the cybersecurity community.</dd>
	<dt><span class="badge badge-danger">recommended</span> <span class="badge badge-primary">blog</span> <span class="badge badge-secondary">insight</span> A. Mulgrew. <!--Aaron Mulgrew--> <a target="_blank" href="https://www.forcepoint.com/blog/x-labs/zero-day-exfiltration-using-chatgpt-prompts">I built a Zero Day virus with undetectable exfiltration using only ChatGPT prompts</a>. Forcepoint. April&nbsp;2023</dt>
	<dd>The blog presents an alarming experiment where the author claims to have successfully exploited the capabilities of ChatGPT to assist in the development of advanced malware, using techniques like steganography to evade detection. The author argues that the ease with which this was achieved exposes vulnerabilities in both AI safeguarding measures and current cybersecurity defenses, highlighting the potential risks of leveraging AI technologies like ChatGPT for malicious purposes.</dd>
	<dt><span class="badge badge-primary">blog</span> <span class="badge badge-secondary">overview</span> A. Daniel. <!--Anthony Daniel--> <a target="_blank" href="https://itbrief.com.au/story/five-ways-cybercriminals-are-making-use-of-chatgpt">Five Ways Cybercriminals are Making Use of ChatGPT</a>. IT Brief Australia. June&nbsp;2023</dt>
	<dd>Ways in which ChatGPT has already been used for attacks.</dd>
	<!--<dt><span class="badge badge-primary">blog</span> <span class="badge badge-secondary">overview</span> J. Chilton. <!-Jim Chilton.-><a target="_blank" href="https://hbr.org/2023/04/the-new-risks-chatgpt-poses-to-cybersecurity">The New Risks ChatGPT Poses to Cybersecurity</a>. Harvard Business Review. April&nbsp;2023</dt>
	<dd>The article discusses the potential cybersecurity risks posed by the widespread adoption of OpenAI's ChatGPT, such as more sophisticated phishing scams and the potential for generating malicious code. It calls for cybersecurity professionals to adapt with advanced detection tools and training, and emphasizes the need for government oversight to regulate AI usage and ensure it doesn't compromise cybersecurity efforts.</dd>-->
</dl>

<h5><a data-toggle="collapse" href="#five" role="button">
    <i class="fas fa-chevron-down"></i> On the other side, AI can help defenders, e.g., in penetration testing.
</a></h5>
<dl class="collapse" id="five">
    <dt><span class="badge badge-primary">tool</span> <span class="badge badge-secondary">example</span> <a target="_blank" href="https://github.com/GreyDGL/PentestGPT">PentestGPT</a></dt>
    <dd>Example of novel defense techniques with AI: A penetration testing tool leveraging LLMs (GPT-4 is recommended). Tries to solve problem of losing required context in penetration testing sessions.</dd>
    <!--<dt><span class="badge badge-primary">blog</span> <span class="badge badge-secondary">overview</span> B. Rezed. <!-Bally Rezed-> <a target="_blank" href="https://ballyrezed.medium.com/ai-and-ml-driving-the-future-of-pen-testing-vapt-82b75eba45de">AI and ML: Driving The Future Of Pen Testing/VAPT</a>. Medium. March&nbsp;2023</dt>
    <dd>The article discusses the growing role of Artificial Intelligence (AI) and Machine Learning (ML) in the field of penetration testing and vulnerability assessment (VAPT), highlighting their ability to improve software performance, efficiently identify issues, and expedite project delivery. It argues that AI and ML technologies not only enhance the security measures against rising cyberattacks but also necessitate careful and ethical implementation to truly fortify cybersecurity efforts.</dd>-->
    <dt><span class="badge badge-danger">recommended</span> <span class="badge badge-primary">research</span> <span class="badge badge-secondary">insight</span> A. Happe, J. Cito. <!-- Andreas Happe, Jürgen Cito. --> <a target="_blank" href="https://arxiv.org/abs/2308.00121">Getting pwn'd by AI: Penetration Testing with Large Language Models</a>. Arxiv. August&nbsp;2023</dt>
    <dd>This paper investigates the use of large-language models like GPT-3.5 in aiding penetration testers for both high-level task planning and low-level vulnerability hunting. The study includes a closed-feedback loop where the AI model suggests and executes attack vectors in a vulnerable virtual machine, and concludes with discussion on the promising initial results and ethical considerations.</dd>
</dl>

<h5><a data-toggle="collapse" href="#six" role="button">
    <i class="fas fa-chevron-down"></i> Generally, AI can assist in (code) security analysis and improvement.
</a></h5>
<dl class="collapse" id="six">
    <dt><span class="badge badge-primary">news</span> <span class="badge badge-secondary">insight</span> B. Nolan. <!--Beatrice Nolan--> <a target="_blank" href="https://www.businessinsider.com/chatgpt-ai-code-develop-software-guide-prompts-2023-7">OpenAI's ChatGPT can write impressive code. Here are the prompts you should use for the best results, experts say</a>. Business Insider. August&nbsp;2023</dt>
    <dd>OpenAI's ChatGPT can generate functional code, intriguing tech leaders and programmers. To improve code quality, experts suggest using clear, specific prompts and assigning ChatGPT a role like "world-class programmer."</dd>
    <!--<dt><span class="badge badge-primary">discussion</span> <span class="badge badge-secondary">overview</span> <a target="_blank" href="https://www.reddit.com/r/codereview/comments/12e6mrd/code_review_assistant_using_chat_gpt/">Discussion on Using ChatGPT as Code Review Assistant</a>. Reddit. Since April&nbsp;2023</dt>
    <dd>Discussion of various Reddit users how ChatGPT can be used effectively for code review.</dd>
	<dt><span class="badge badge-primary">research</span> <span class="badge badge-secondary">insight</span> N. Perry et al. <!-Neil Perry, Megha Srivastava, Deepak Kumar, Dan Boneh.-> <a target="_blank" href="https://arxiv.org/abs/2211.03622">Do Users Write More Insecure Code with AI Assistants?</a>. December 2022</dt>
	<dd>A large-scale user study, finding that participants using an AI Code assistant wrote less secure code but were more confident in its security than those not using the assistant. Those who were skeptical of the AI and actively engaged with it produced more secure code, offering insights for the design of future AI-based code assistants.</dd>-->
	<!--<dt><span class="badge badge-primary">webpage</span> <span class="badge badge-secondary">overview</span> IBM. <a target="_blank" href="https://www.ibm.com/security/artificial-intelligence">AI for cybersecurity. &nbsp;2023</a></dt>
	<dd>Landing page providing an overview of how AI can support cybersecurity investigation, identification, and reporting. Highlighting benefits and IBM's solution and providing a number of case studies.</dd>-->
	<!--<dt><span class="badge badge-primary">blog</span> <span class="badge badge-secondary">overview</span> Trend Micro. <a target="_blank" href="https://www.trendmicro.com/en_ca/devops/23/e/chatgpt-security-vulnerabilities.html">Security Vulnerabilities of ChatGPT-Generated Code</a>. May&nbsp;2023</dt>
	<dd>Despite OpenAI's security measures, ChatGPT-generated code can contain vulnerabilities and lacks essential security features, making it prone to exploitation. Developers are advised to treat such AI-generated code as potentially insecure and to use ChatGPT as a supplementary tool, backed by manual coding and rigorous security testing.</dd>-->
</dl>

<h5><a data-toggle="collapse" href="#seven" role="button">
    <i class="fas fa-chevron-down"></i> Potentially, AI raises the bar for both attackers and defenders.
</a></h5>
<dl class="collapse" id="seven">
    <dt><span class="badge badge-primary">blog</span> <span class="badge badge-secondary">insight</span> D. Merian. <!--David Merian--> <a target="_blank" href="https://systemweakness.com/chatgpt-cve-analysis-for-red-team-5e5bacc67f31">ChatGPT CVE Analysis for Red and Blue Team</a>. Medium. March&nbsp;2023</dt>
    <dd>The article discusses how ChatGPT can be used by both Red Teams and Blue Teams for CVE (Common Vulnerabilities and Exposures) analysis, helping the Red Team exploit vulnerabilities and the Blue Team understand and defend against them. Using a test scenario of CVE-2017–7494, a remote code execution vulnerability in Samba, the article confirms that ChatGPT can effectively analyze code for vulnerabilities and suggests potential attack sequences.</dd>
</dl>

<h5><a data-toggle="collapse" href="#eight" role="button">
    <i class="fas fa-chevron-down"></i> To ensure defenders keep up, we urgently need practice and training.
</a></h5>
<dl class="collapse" id="eight">
    <dt><span class="badge badge-danger">recommended</span> <span class="badge badge-primary">survey</span> <span class="badge badge-secondary">broad insight</span> Harvard Business Review Analytic Services. <a target="_blank" href="https://hbr.org/sponsored/2018/11/artificial-intelligence">Artificial Intelligence</a>. November&nbsp;2018</dt>
    <dd>The adoption of Artificial Intelligence (AI) and Machine Learning (ML) in businesses is rapidly increasing, with larger organizations being more likely to currently utilize these technologies. The technologies offer a wide range of benefits including predictive analytics, anomaly detection, and improved customer experience, thus attracting attention from senior executives; however, challenges like a skills gap and the technical complexity of AI/ML remain.</dd>
	<dt><span class="badge badge-danger">recommended</span> <span class="badge badge-primary">blog</span> <span class="badge badge-secondary">insight</span> K. Renaud, M. Warkentin, G. Westerman. <!--Karen Renaud, Merrill Warkentin, George Westerman.--> <a target="_blank" href="https://sloanreview.mit.edu/article/from-chatgpt-to-hackgpt-meeting-the-cybersecurity-threat-of-generative-ai/">From ChatGPT to HackGPT: Meeting the Cybersecurity Threat of Generative AI</a>. MIT Sloan Management Review. April&nbsp;2023</dt>
	<dd>The article warns that the rise of generative AI tools like ChatGPT poses new and sophisticated cybersecurity challenges for businesses, moving from mass attacks to highly personalized and intelligent threats that can bypass traditional security measures. To defend against these evolving threats, companies need to adopt real-time adaptive strategies that include employing generative AI for defense, enhancing anomaly detection, and shifting from rule-based employee training to knowledge-based preparedness.</dd>
    <dt><span class="badge badge-primary">course</span> <span class="badge badge-secondary">example</span> D.R. Pothula. <!--Dharmanandana Reddy Pothula--> <a target="_blank" href="https://www.udemy.com/course/mastering-ai-chatgpt-in-advanced-ethical-hacking-volume-1/">Advanced Ethical Hacking: Mastery AI & ChatGPT</a>. Udemy. July&nbsp;2023</dt>
    <dd>An eight-module educational program exploring the intersection of AI and ethical hacking, focusing on advanced techniques and the role of ChatGPT, along with the risks and countermeasures involved.</dd>
</dl>

<h5><a data-toggle="collapse" href="#nine" role="button">
    <i class="fas fa-chevron-down"></i> Current AI has many limitations and challenges, including security and privacy.
</a></h5>
<dl class="collapse" id="nine">
	<!--<dt><span class="badge badge-primary">blog</span> <span class="badge badge-secondary">overview</span> Inside Big Data. <a target="_blank" href="https://insidebigdata.com/2023/05/02/why-chatgpt-is-a-cyber-threat-to-businesses/"> Why ChatGPT is a Cyber Threat to Businesses</a>. May&nbsp;2023</dt>
	<dd>The article delves into the cybersecurity risks posed by the increasing use of AI-powered chatbots like ChatGPT, from their exploitation in social engineering attacks to sensitive data leaks. It also offers practical advice for businesses on how to safeguard against these vulnerabilities, emphasizing employee education, robust risk assessment, and investment in cybersecurity tools.</dd>-->
	<!--<dt><span class="badge badge-primary">research</span> <span class="badge badge-secondary">broad insight</span> N. Risse, M. Böhme. <!-Niklas Risse, Marcel Böhme-> <a target="_blank" href="https://arxiv.org/abs/2306.17193">Limits of Machine Learning for Automatic Vulnerability Detection</a>. arXiv. June&nbsp;2023</dt>
	<dd>Deep dive into the limitations of AI-based defect prediction on source code. Analyses how dataset amplification improves prediction robustness.</dd>-->
	<dt><span class="badge badge-primary">blog</span> <span class="badge badge-secondary">insight</span> W. Knight. <!--Will Knight--> <a target="_blank" href="https://www.wired.com/story/ai-adversarial-attacks/">A New Attack Impacts Major AI Chatbots—and No One Knows How to Stop It</a>. Wired. August&nbsp;2023</dt>
	<dd>Researchers at CMU found that security guardrails of current LLMs can be easily avoided by making small, simple additions to the prompt. Zico Kolter: "We just don't know how to make them secure."</dd>
	<!--<dt><span class="badge badge-primary">blog</span> <span class="badge badge-secondary">insight</span> Check Point. <a target="_blank" href="https://blog.checkpoint.com/2023/02/07/cybercriminals-bypass-chatgpt-restrictions-to-generate-malicious-content/">Cybercriminals Bypass ChatGPT Restrictions to Generate Malicious Content</a>. February&nbsp;2023</dt>
	<dd>Two examples of hacker discussions on bypassing anti-abuse restrictions in ChatGPT.</dd>-->
	<dt><span class="badge badge-danger">recommended</span> <span class="badge badge-primary">blog</span> <span class="badge badge-secondary">insight</span> R. Lemos. <!--Robert Lemos--> <a target="_blank" href="https://www.darkreading.com/risk/employees-feeding-sensitive-business-data-chatgpt-raising-security-fears">Employees Are Feeding Sensitive Biz Data to ChatGPT, Raising Security Fears</a>. Dark Reading. March&nbsp;2023</dt>
	<dd>The article highlights the growing cybersecurity concerns as employees increasingly input sensitive business and personal information into large language models like ChatGPT, risking data leakage and legal complications for companies. It cites instances of misuse, discusses the potential for "training data extraction attacks," and suggests that employee education and corporate policies are key to mitigating these risks.</dd>
	<!--<dt><span class="badge badge-primary">blog</span> <span class="badge badge-secondary">insight</span> G. Cluley. <!-Graham Cluley-> <a target="_blank" href="https://www.bitdefender.com/blog/hotforsecurity/100-000-hacked-chatgpt-accounts-up-for-sale-on-the-dark-web/">100,000 hacked ChatGPT accounts up for sale on the dark web</a>. Bitdefender. June&nbsp;2023</dt>
	<dd>Over 100,000 hacked ChatGPT accounts were found on the dark web, according to Group-IB researchers. The stolen credentials, obtained mainly via Raccoon malware, risk unauthorized access to sensitive work data and other online accounts if passwords are reused.</dd>-->
    <!--<dt><span class="badge badge-primary">blog</span> <span class="badge badge-secondary">insight</span> Harish SG. <a target="_blank" href="https://infosecwriteups.com/jail-breaking-chatgpt-to-write-malware-9b3ae111f30c">Jail breaking ChatGPT to write malware</a>. Medium. July&nbsp;2023</dt>
    <dd>Security researcher Harish SG demonstrated how he "jailbroke" ChatGPT to act outside its typical ethical and functional parameters, enabling it to write malware scripts and evade OpenAI's restrictions. He suggests using a layered security approach including deny-listing, blacklisting, and input/output sanitization to better defend language models like ChatGPT against similar exploits.</dd>-->
    <dt><span class="badge badge-primary">research</span> <span class="badge badge-secondary">insight</span> B. Xu et al. <!--Bowen Xu, Thanh-Dat Nguyen, Thanh Le-Cong, Thong Hoang, Jiakun Liu, Kisub Kim, Chen Gong, Changan Niu, Chenyu Wang, Bach Le, David Lo.--> <a target="_blank" href="https://arxiv.org/abs/2307.09765">Are We Ready to Embrace Generative AI for Software Q&A?</a>. ASE NIER. August&nbsp;2023</dt>
    <dd>A study compareing the quality of human-written and ChatGPT-generated answers on Stack Overflow, concluding that while both types are semantically similar, human answers outperform ChatGPT's by 10% overall. Stack Overflow had previously banned ChatGPT, citing the AI's low-quality responses as the reason.</dd>
</dl>

<h5><a data-toggle="collapse" href="#ten" role="button">
    <i class="fas fa-chevron-down"></i> Lastly, AI regulation is still in early progress.
</a></h5>
<dl class="collapse" id="ten">
	<dt><span class="badge badge-primary">news</span> <span class="badge badge-secondary">overview</span> C. Kang. <!--Cecilia Kang--> <a target="_blank" href="https://www.nytimes.com/2023/07/21/technology/ai-united-states-regulation.html">In U.S., Regulating A.I. Is in Its ‘Early Days’</a>. The New York Times. July&nbsp;2023</dt>
    <dd>Despite increased attention and activity by U.S. lawmakers and the White House regarding artificial intelligence (A.I.) regulations, concrete rules for the technology are still far from being established. In contrast to Europe, where A.I. legislation is set to be enacted, the U.S. is in the early stages of a likely long and difficult process, facing a lack of consensus among stakeholders and lawmakers on how to handle the rapidly evolving technology.</dd>
	<dt><span class="badge badge-danger">recommended</span> <span class="badge badge-primary">white paper</span> <span class="badge badge-secondary">broad insight</span> Hollistic AI. <a target="_blank" href="https://www.holisticai.com/papers/the-state-of-ai-regulations-in-2023">The State of AI Regulations in 2023</a>. January&nbsp;2023</dt>
    <dd>Detailed summary of the ongoing AI-related regulation activities in the US, EU, UK, and China.</dd>
	<dt><span class="badge badge-primary">white paper</span> <span class="badge badge-secondary">guide</span> European Union Agency for Cybersecurity (ENISA).  <a target="_blank" href="https://www.enisa.europa.eu/publications/multilayer-framework-for-good-cybersecurity-practices-for-ai">Multilayer Framework for Good Cybersecurity Practices for AI</a>. June&nbsp;2023</dt>
	<dd>Guidelines for national authorities and AI stakeholders to ensure security of AI-based systems. The proposed FAICP framework proposes three layers of cybersecurity practices and discusses open issues in all of them.</dd>
	<dt><span class="badge badge-primary">white paper</span> <span class="badge badge-secondary">guide</span> World Economic Forum. <a target="_blank" href="https://www.weforum.org/reports/adopting-ai-responsibly-guidelines-for-procurement-of-ai-solutions-by-the-private-sector"> Adopting AI Responsibly: Guidelines for Procurement of AI Solutions by the Private Sector</a>. June&nbsp;2023</dt>
	<dd>Guidelines for the ethical adoption of AI technology in the industry.</dd>
	<dt><span class="badge badge-danger">recommended</span> <span class="badge badge-primary">blog</span> <span class="badge badge-secondary">insight</span> OpenAI. <a target="_blank" href="https://openai.com/blog/introducing-chatgpt-enterprise">Introducing ChatGPT Enterprise</a>. August&nbsp;2023</dt>
	<dd>OpenAI's release article for <a target="_blank" href="https://openai.com/enterprise">ChatGPT Enterprise</a>, addressing some Enterprise issues regarding trust, risk, and security. It announces further developments in this direction.</dd>
</dl>